\chapter{\textbf{Introduction}}

\label{Introduction}

Cloud computing has attracted a lot of attention lately. It was popularized as a business model by Amazon's Elastic Compute Cloud (EC2), which started selling virtual machines (VMs) in 2006. Over time, more cloud providers have appeared in the market, offering their computational resources (CPU, memory, and I/O bandwidth). This provision model based on outsourcing is known  as Infrastructure-as-a-service (IaaS). One of its most appealing benefits is the ability to cut costs. Companies may base their IT strategies on cloud-based resources, spending very little or no money managing their own IT infrastructure. They pay for these resources on-demand, in contrast to the traditional resource provisioning model, in which they would need to deal with both under- and over- utilization of their own resources. Moreover, the cloud providers may offer lower prices because they are benefited from the economy of 
scale.


These gains are seen on public clouds -- clouds made available in a pay-as-you-go manner to the public by an external provider. Although the market has evolved around this type of cloud, organizations might build IaaS clouds using their own infrastructure, known as private clouds. Their aim is not to sell capacity  over the internet,  but to give local users an agile and flexible infrastructure to run service workloads in their administrative domains. These users are offered virtual machines (VMs), which are scheduled in a group of physical machines within their organization, which we call a cluster. This leads to a better utilization of resources, since services with little demand can be packed into the same machine, process known as server consolidation. This means that on private clouds there is also the possibility to cut IT costs, since the consolidation aims to minimize the number of physical servers needed. Other benefits, such as the migration of VMs between hosts and the ability to dynamically change the 
amount of resources provided to it, enabled by technology present in virtual machine monitors (VMMs), make it 
possible to deal with fluctuations in the workload. These characteristics propitiate an elastic environment, which is good for a private cloud, and vital for the pay-on-demand model used in public clouds.  It is also possible for an organization to mix these two types of clouds, creating a hybrid cloud,  which is useful to supplement a private cloud's infrastructure with external resources from a public one. However, this paper will focus on a private cloud environment. 

\section{Context}

A cloud is highly dependable on machine virtualization, essential to achieve its goals. Database management systems (DBMSes), like other software systems, are also increasingly being run on virtualized environments for many reasons. Some of them are mentioned in \cite{4498282}, \cite{4401021} and \cite{Soror:2008:AVM:1376616.1376711}, which include the reduction on the cost of ownership, better provisioning and manageability of applications and the ability to migrate them among physical hosts. Our paper is motivated by the possibility to take a variety of databases that run on dedicated computing resources and move them to a shared resource pool, on a private cloud, process known as \textit{Database Consolidation}. This scenario is discussed in \cite{instance1290}, in which it is given a good example of how consolidation is applied in a production environment. It lists two deployment models in which this process may be performed onto a private cloud. 

In our paper, the deployment model considered is the \textit{Infrastructure Cloud} model, illustrated in figure  ~\ref{fig:infra-model}. In this model, there is generally a one-to-many relationship between servers and VM guests, considered by this paper. When a database service is requested, the whole operating system stack is built and provided. Elasticity in this model is limited. Although VM guests may be provided more virtual resources ( CPU or Memory ), they cannot span across servers ( i.e. they are limited to the resources from the server they are running on ). This means that the full resources of the private cloud cannot be brought to bear on a workload requirement. However, the guests will be able to benefit from the live migration feature, supported by most hypervisors, and thus be moved to a host with more resource availability. 

\begin{figure}[ht]
\centering
\includegraphics[width=0.5\textwidth]{infra-model.png}
\caption{Infrastructure cloud deployment model}
\label{fig:infra-model}
\end{figure} 

Some considerations should be made before adopting this deployment model. First, the virtualization will not reduce the number of DBMSes and operating systems, which will surely result in an overhead. It also will not probably be as high performing as other existing non-virtualized alternatives, as I/O intensive workloads may not perform as well in virtualized environments. However, it provides high fault and resource isolation, straightforward database deployment via VM templates and  support for multiple DBMS versions and configurations.


\section{Objective}

The problem addressed by our paper is formalized in \cite{4401021}, which defined it as the \textit{Virtualization Design Problem} (i.e. resource consolidation problem ) for relational database workloads. It can be defined as follows: \textit{"Given N database workloads that will run on N database systems inside N virtual 
machines, how should we allocate the available resources to these N virtual machines to get the best overall performance?"}. According to the mentioned paper, this problem may find a better solution when applied to relational database systems due to three factors. First, relational database workloads consist of SQL queries with constrained and highly specialized resource usage patterns. Second , queries are highly variable in the way they use resources -- one query might heavily need CPU, while another might need I/O bandwidth instead. Thus, they could benefit from the dynamism in resource allocation. Third, database systems already have a way of modelling their own performance, namely the query optimizer.

As mentioned, DBMSes have particularities involving their workloads. Therefore, the application running inside a VM should not be treated as a black box. Instead, the database system cost model should be exploited. As VMMs have parameters to control the share of physical resources, database systems also have tuning parameters to manage their own performance. These two sets need to be simultaneously analyzed and tuned. In \cite{Soror:2008:AVM:1376616.1376711}, this is a principle of its proposed \textit{virtualization design advisor}. It works by recommending configuration parameters for a group of VMs, each one containing a DBMS. These parameters determine how the shared resources will be allocated to each VM, and consequently to each DBMS. It uses information about anticipated workloads to specify these parameters offline. Furthermore, runtime information collected after the deployment of the recommended configuration can be used to refine this recommendation and to handle fluctuations in the workload. However, this advisor was not originally created to be run on a cloud, rather it has been implemented and tested on a single physical machine, in which two DBMS instances were deployed.

This paper serves to describe our implementation of the virtualization design advisor in a cloud environment. Our objective is to solve the \textit{Virtualization Design Problem} in a distributed manner. For each host in a private cloud, we create a corresponding instance of our advisor. Each instance will optimize the CPU among several database workloads. This differs form the scenario considered in \cite{Soror:2008:AVM:1376616.1376711}. Instead of deploying the virtual machines on a single server, we consider a private cloud in our scenario. However, the way our advisor works does not differ from the original because hosts inside a private cloud don't share resources. Other difference is that our implementation focus only on CPU because  generally the query optimization performed by DBMSes is highly sensitive to this resource. They often have one or more tuning parameters used to describe it. By improving the reallocation of the CPU, we expect significant changes in the plans and execution times of the queries. The support of multiple resource types is left for future work. In \cite{Storm:2006:ASM:1182635.1164220} and \cite{springerlink:10.1007/3-540-44469-6_9}, the dynamic reallocation of other resources is discussed. \cite{Soror:2008:AVM:1376616.1376711} also gives an overview on how to model the cost variation of multiple resources.


%Even though in \cite{Soror:2008:AVM:1376616.1376711} the advisor is said to support multiple resource types, this paper is restricted to the consolidation of CPU.

Because of the modular architecture of the advisor proposed in \cite{Soror:2008:AVM:1376616.1376711}, our implementation follows the same approach and splits the advisor into several classes. It is responsible for running and analyzing the database workloads  at the same time. First, it gives each one of them a certain CPU allocation, according to estimates. While a workload is being run, it corrects for any estimation errors and also detects changes in the workload ( i.e. whether it is becoming more or less CPU intensive ). This implementation was developed to work along a virtual infrastructure manager, namely OpenNebula, responsible for managing the private cloud. This integration has a lot of benefits. First, it makes it easier to obtain information about cloud objects, including virtual machines, hosts, etc. Our advisor can also make use of scripts and features already included in this manager. Furthermore, we are able to integrate any other third-party solution build for OpenNebula with our advisor. In this paper, we detail how we were able to integrate our advisor to this manager. In addition, we comment OpenNebula's limitations, and how they were overcome in order to develop our solution.

In this implementation, our focus is to optimize the CPU allocation among database workloads. However, our idea is that this could be expanded in a future work, in order to support multiple resource types. Therefore, in this paper our objective is not to show a final and complete solution to the virtualization design problem. Here we introduce this problem and we show that just by reallocating one resource, we can improve the performance of running database workloads in a cloud. 

The rest of this paper is structured as follows. Chapter ~\ref{chap:relwork} is used to discuss related work, including the description of the \textit{virtualization design advisor}. Chapter ~\ref{chap:infrastructure} is used to show how a cloud infrastructure is managed. In chapter ~\ref{chap:implementation}, we show how the integration of the advisor within the cloud management system was implemented. Chapter ~\ref{chap:results} is used to show the results obtained. Finally, chapter ~\ref{chap:final} presents some final considerations and ideas for future work.

